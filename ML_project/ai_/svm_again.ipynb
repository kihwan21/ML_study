{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력변수(학습데이터):  (73, 4)\n",
      "입력변수(검증데이터):  (32, 4)\n",
      "종속변수(학습데이터):  (73,)\n",
      "종속변수(검증데이터):  (32,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder  # 범주형 자료 실수화\n",
    "from sklearn.model_selection import train_test_split    # 학습데이터 나누기\n",
    "\n",
    "\n",
    "xy_data = pd.read_csv('C:/my_study_python_work_space/ML_project/kaggle/iris-train.csv')     # 학습 데이터 가져오기\n",
    "X_test = pd.read_csv(\"C:/my_study_python_work_space/ML_project/kaggle/iris-test.csv\")       # 테스트 데이터 가져오기\n",
    "\n",
    "classle = LabelEncoder() # train 데이터셋에 speices가 문자열\n",
    "\n",
    "#학습데이터 X, y\n",
    "X = xy_data.drop('species', axis=1) # 학습데이터 입력변수 종을 맞춰야 하니까 species에 관한 열을 없애버림. axis 1은 row 제거. 즉, 테이블 이름도 같이 drop\n",
    "y = classle.fit_transform(xy_data['species'].values)             # 학습데이터 종속변수 그 중에서 종에 대한 데이터셋 \n",
    "\n",
    "# train_test_split()\n",
    "#X(입력변수)와 y(종속변수)로 이루어진 데이터를 학습과 확인 데이터셋으로 각각 70% 30%의 비율로 나눔  즉, 검증(valid)을 전체 데이터중 30% \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.3, random_state=3, stratify=y) \n",
    "\n",
    "\n",
    "print('입력변수(학습데이터): ',  X_train.shape)\n",
    "print('입력변수(검증데이터): ', X_valid.shape)\n",
    "print('종속변수(학습데이터): ',  y_train.shape)\n",
    "print('종속변수(검증데이터): ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split() 함수\n",
    "test_size : 테스트 데이터셋 구성 비율 (default = 0.25)\n",
    "shuffle :  split을 수행하기 전에 데이터를 섞을 것인지의 여부 (default = True)\n",
    "stratify : 분류를 위한 중요한 옵션으로 데이터셋 분할 시 class 비율 유지 \n",
    "random state : 데이터셋을 섞을 때 해당 int 값을 보고 섞으며, 하이퍼파라미터 튜닝시 이 값을 고정하고 투닝해야 매번 데이터셋이 변경되는 것을 방지할 수 있음. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(gamma='auto', C=5) # c는 사용자가 임의로 지정해야 하는 값으로 크게하면 Margin이 작아짐 즉, 오버피팅 발생 가능성 / 적게하면 Margin이 커짐 즉, underfitting 가능성 / gamma는 모델의 복잡도 gamma는 가우시안 커널을 변경함. 즉 결정 경계의 곡률을 결정한다.\n",
    "#(작은 gamma 값 : 모델의 복잡도를 낮춤 / 큰 gamma 값 : 모델의 복잡도를 높임)\n",
    "\n",
    "model.fit(X_train, y_train) # 모델 학습\n",
    "\n",
    "y_train_pred = model.predict(X_train)   # 학습데이터 예측\n",
    "y_valid_pred = model.predict(X_valid)   # 검증데이터 예측\n",
    "\n",
    "# 정확도\n",
    "from sklearn.metrics import accuracy_score #정확도 계산을 위한 모듈 import\n",
    "print(accuracy_score(y_valid, y_valid_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5e9acfa9e81c6dc9dade1ddfb0eacd10fb82856ca55f7e1427b6e32fc559d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
